
spring.config.import=security.properties
# Required connection configs for Kafka producer, consumer, and admin
spring.kafka.properties.sasl.mechanism=PLAIN
spring.kafka.properties.bootstrap.servers=${bootstrap.servers}
spring.kafka.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='${user}' password='${password}';
spring.kafka.properties.security.protocol=SASL_SSL

# Best practice for higher availability in Apache Kafka clients prior to 3.0
spring.kafka.properties.session.timeout.ms=45000

# Required connection configs for Confluent Cloud Schema Registry
spring.kafka.properties.basic.auth.credentials.source=USER_INFO
spring.kafka.properties.basic.auth.user.info=${user.sr}:${password.sr}
spring.kafka.properties.schema.registry.url=${bootstrap.servers.schema.registry}

#Consumer Configs
spring.kafka.listener.ack-mode=manual
spring.kafka.listener.log-container-config=true
spring.kafka.listener.idle-event-interval=30000

spring.kafka.bootstrap-servers[0]=localhost:9092

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.client-id=transactional-consumer
spring.kafka.consumer.enable-auto-commit=false
spring.kafka.consumer.group-id=transactional-consumer-group
spring.kafka.consumer.isolation-level=read_committed
spring.kafka.consumer.max-poll-records=50

spring.kafka.consumer.key-deserializer=org.springframework.kafka.support.serializer.ErrorHandlingDeserializer
spring.kafka.consumer.properties.spring.deserializer.key.delegate.class=org.apache.kafka.common.serialization.StringDeserializer

spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
#spring.kafka.consumer.properties.spring.deserializer.value.delegate.class=org.springframework.kafka.support.serializer.JsonDeserializer
#spring.kafka.consumer.properties.spring.json.value.default.type=com.example.transactional.consumer.domain.Student
#spring.kafka.consumer.properties.spring.json.type.mapping=student:com.example.transactional.consumer.domain.Student